{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-18T17:26:53.073624Z",
     "start_time": "2025-04-18T17:26:51.245048Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "from nltk.book import sent1"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T17:27:26.331981Z",
     "start_time": "2025-04-18T17:27:25.821722Z"
    }
   },
   "cell_type": "code",
   "source": "df = pd.read_csv('IMDB Dataset.csv')",
   "id": "82de1a5151b98743",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T17:27:29.297671Z",
     "start_time": "2025-04-18T17:27:29.287302Z"
    }
   },
   "cell_type": "code",
   "source": "df",
   "id": "10a65f3508d14369",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                                  review sentiment\n",
       "0      One of the other reviewers has mentioned that ...  positive\n",
       "1      A wonderful little production. <br /><br />The...  positive\n",
       "2      I thought this was a wonderful way to spend ti...  positive\n",
       "3      Basically there's a family where a little boy ...  negative\n",
       "4      Petter Mattei's \"Love in the Time of Money\" is...  positive\n",
       "...                                                  ...       ...\n",
       "49995  I thought this movie did a down right good job...  positive\n",
       "49996  Bad plot, bad dialogue, bad acting, idiotic di...  negative\n",
       "49997  I am a Catholic taught in parochial elementary...  negative\n",
       "49998  I'm going to have to disagree with the previou...  negative\n",
       "49999  No one expects the Star Trek movies to be high...  negative\n",
       "\n",
       "[50000 rows x 2 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>I thought this movie did a down right good job...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>Bad plot, bad dialogue, bad acting, idiotic di...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>I am a Catholic taught in parochial elementary...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>I'm going to have to disagree with the previou...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>No one expects the Star Trek movies to be high...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows Ã— 2 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T17:27:39.049308Z",
     "start_time": "2025-04-18T17:27:39.044987Z"
    }
   },
   "cell_type": "code",
   "source": "df.shape",
   "id": "d460a700d7c18b82",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 2)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T17:27:45.169484Z",
     "start_time": "2025-04-18T17:27:45.165168Z"
    }
   },
   "cell_type": "code",
   "source": "df.head",
   "id": "5838450697bc68a5",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of                                                   review sentiment\n",
       "0      One of the other reviewers has mentioned that ...  positive\n",
       "1      A wonderful little production. <br /><br />The...  positive\n",
       "2      I thought this was a wonderful way to spend ti...  positive\n",
       "3      Basically there's a family where a little boy ...  negative\n",
       "4      Petter Mattei's \"Love in the Time of Money\" is...  positive\n",
       "...                                                  ...       ...\n",
       "49995  I thought this movie did a down right good job...  positive\n",
       "49996  Bad plot, bad dialogue, bad acting, idiotic di...  negative\n",
       "49997  I am a Catholic taught in parochial elementary...  negative\n",
       "49998  I'm going to have to disagree with the previou...  negative\n",
       "49999  No one expects the Star Trek movies to be high...  negative\n",
       "\n",
       "[50000 rows x 2 columns]>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T17:27:56.766230Z",
     "start_time": "2025-04-18T17:27:56.759873Z"
    }
   },
   "cell_type": "code",
   "source": "df.head(100)",
   "id": "4cc9741f3ee6aa54",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                               review sentiment\n",
       "0   One of the other reviewers has mentioned that ...  positive\n",
       "1   A wonderful little production. <br /><br />The...  positive\n",
       "2   I thought this was a wonderful way to spend ti...  positive\n",
       "3   Basically there's a family where a little boy ...  negative\n",
       "4   Petter Mattei's \"Love in the Time of Money\" is...  positive\n",
       "..                                                ...       ...\n",
       "95  Daniel Day-Lewis is the most versatile actor a...  positive\n",
       "96  My guess would be this was originally going to...  negative\n",
       "97  Well, I like to watch bad horror B-Movies, cau...  negative\n",
       "98  This IS the worst movie I have ever seen, as w...  negative\n",
       "99  I have been a Mario fan for as long as I can r...  positive\n",
       "\n",
       "[100 rows x 2 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Daniel Day-Lewis is the most versatile actor a...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>My guess would be this was originally going to...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Well, I like to watch bad horror B-Movies, cau...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>This IS the worst movie I have ever seen, as w...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>I have been a Mario fan for as long as I can r...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 2 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T17:28:47.694515Z",
     "start_time": "2025-04-18T17:28:47.600512Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# lower case\n",
    "df['review'] = df['review'].str.lower()"
   ],
   "id": "179f3d90c2769b6e",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T17:28:52.209527Z",
     "start_time": "2025-04-18T17:28:52.204220Z"
    }
   },
   "cell_type": "code",
   "source": "df",
   "id": "a92723a77954d9db",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                                  review sentiment\n",
       "0      one of the other reviewers has mentioned that ...  positive\n",
       "1      a wonderful little production. <br /><br />the...  positive\n",
       "2      i thought this was a wonderful way to spend ti...  positive\n",
       "3      basically there's a family where a little boy ...  negative\n",
       "4      petter mattei's \"love in the time of money\" is...  positive\n",
       "...                                                  ...       ...\n",
       "49995  i thought this movie did a down right good job...  positive\n",
       "49996  bad plot, bad dialogue, bad acting, idiotic di...  negative\n",
       "49997  i am a catholic taught in parochial elementary...  negative\n",
       "49998  i'm going to have to disagree with the previou...  negative\n",
       "49999  no one expects the star trek movies to be high...  negative\n",
       "\n",
       "[50000 rows x 2 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>one of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a wonderful little production. &lt;br /&gt;&lt;br /&gt;the...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>petter mattei's \"love in the time of money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>i thought this movie did a down right good job...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>bad plot, bad dialogue, bad acting, idiotic di...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>i am a catholic taught in parochial elementary...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>i'm going to have to disagree with the previou...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>no one expects the star trek movies to be high...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows Ã— 2 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T17:29:23.842154Z",
     "start_time": "2025-04-18T17:29:23.838623Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# removal html tags\n",
    "import re\n",
    "def remove_html_tags(text):\n",
    "    clean = re.compile('<.*?>')\n",
    "    return re.sub(clean, '', text)"
   ],
   "id": "1950a0678c4ffc17",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T17:29:50.057773Z",
     "start_time": "2025-04-18T17:29:49.925396Z"
    }
   },
   "cell_type": "code",
   "source": "df['review'] = df['review'].apply(remove_html_tags)",
   "id": "c4b3534a2e91c41f",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T17:29:54.008731Z",
     "start_time": "2025-04-18T17:29:54.002710Z"
    }
   },
   "cell_type": "code",
   "source": "df",
   "id": "7f04521e35cd3b8e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                                  review sentiment\n",
       "0      one of the other reviewers has mentioned that ...  positive\n",
       "1      a wonderful little production. the filming tec...  positive\n",
       "2      i thought this was a wonderful way to spend ti...  positive\n",
       "3      basically there's a family where a little boy ...  negative\n",
       "4      petter mattei's \"love in the time of money\" is...  positive\n",
       "...                                                  ...       ...\n",
       "49995  i thought this movie did a down right good job...  positive\n",
       "49996  bad plot, bad dialogue, bad acting, idiotic di...  negative\n",
       "49997  i am a catholic taught in parochial elementary...  negative\n",
       "49998  i'm going to have to disagree with the previou...  negative\n",
       "49999  no one expects the star trek movies to be high...  negative\n",
       "\n",
       "[50000 rows x 2 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>one of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a wonderful little production. the filming tec...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>petter mattei's \"love in the time of money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>i thought this movie did a down right good job...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>bad plot, bad dialogue, bad acting, idiotic di...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>i am a catholic taught in parochial elementary...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>i'm going to have to disagree with the previou...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>no one expects the star trek movies to be high...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows Ã— 2 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T17:30:54.540078Z",
     "start_time": "2025-04-18T17:30:54.536983Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# removal urls\n",
    "def remove_urls(text):\n",
    "    return re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)"
   ],
   "id": "eaa0931c54073bd5",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T17:31:02.198370Z",
     "start_time": "2025-04-18T17:31:01.846158Z"
    }
   },
   "cell_type": "code",
   "source": "df['review'] = df['review'].apply(remove_urls)",
   "id": "235d2c437c17993",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T17:32:11.624528Z",
     "start_time": "2025-04-18T17:32:11.620921Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# punctuation handeling\n",
    "import string,time\n",
    "def remove_punctuation(text):\n",
    "    return text.translate(str.maketrans('', '', string.punctuation))"
   ],
   "id": "b81517b4f6b34694",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T17:32:14.551631Z",
     "start_time": "2025-04-18T17:32:13.467622Z"
    }
   },
   "cell_type": "code",
   "source": "df['review'] = df['review'].apply(remove_punctuation)",
   "id": "6e49934e2d04c93d",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T17:46:07.710738Z",
     "start_time": "2025-04-18T17:46:07.705691Z"
    }
   },
   "cell_type": "code",
   "source": [
    "chat_words = {\n",
    "    'AFAIK':'As Far As I Know',\n",
    "    'AFK':'Away From Keyboard',\n",
    "    'ASAP':'As Soon As Possible'\n",
    "}\n",
    "\n",
    "\n",
    "{\n",
    "    \"FYI\": \"For Your Information\",\n",
    "    \"ASAP\": \"As Soon As Possible\",\n",
    "    \"BRB\": \"Be Right Back\",\n",
    "    \"BTW\": \"By The Way\",\n",
    "    \"OMG\": \"Oh My God\",\n",
    "    \"IMO\": \"In My Opinion\",\n",
    "    \"LOL\": \"Laugh Out Loud\",\n",
    "    \"TTYL\": \"Talk To You Later\",\n",
    "    \"GTG\": \"Got To Go\",\n",
    "    \"TTYT\": \"Talk To You Tomorrow\",\n",
    "    \"IDK\": \"I Don't Know\",\n",
    "    \"TMI\": \"Too Much Information\",\n",
    "    \"IMHO\": \"In My Humble Opinion\",\n",
    "    \"ICYMI\": \"In Case You Missed It\",\n",
    "    \"AFAIK\": \"As Far As I Know\",\n",
    "    \"BTW\": \"By The Way\",\n",
    "    \"FAQ\": \"Frequently Asked Questions\",\n",
    "    \"TGIF\": \"Thank God It's Friday\",\n",
    "    \"FYA\": \"For Your Action\",\n",
    "    \"ICYMI\": \"In Case You Missed It\",\n",
    "}"
   ],
   "id": "2fbc91095b6a0127",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'FYI': 'For Your Information',\n",
       " 'ASAP': 'As Soon As Possible',\n",
       " 'BRB': 'Be Right Back',\n",
       " 'BTW': 'By The Way',\n",
       " 'OMG': 'Oh My God',\n",
       " 'IMO': 'In My Opinion',\n",
       " 'LOL': 'Laugh Out Loud',\n",
       " 'TTYL': 'Talk To You Later',\n",
       " 'GTG': 'Got To Go',\n",
       " 'TTYT': 'Talk To You Tomorrow',\n",
       " 'IDK': \"I Don't Know\",\n",
       " 'TMI': 'Too Much Information',\n",
       " 'IMHO': 'In My Humble Opinion',\n",
       " 'ICYMI': 'In Case You Missed It',\n",
       " 'AFAIK': 'As Far As I Know',\n",
       " 'FAQ': 'Frequently Asked Questions',\n",
       " 'TGIF': \"Thank God It's Friday\",\n",
       " 'FYA': 'For Your Action'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "198033bb2bc9a006"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T17:46:25.475024Z",
     "start_time": "2025-04-18T17:46:25.472244Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def chat_conversion(text):\n",
    "    new_text = []\n",
    "    for w in text.split():\n",
    "        if w.upper() in chat_words:\n",
    "            new_text.append(chat_words[w.upper()])\n",
    "        else:\n",
    "            new_text.append(w)\n",
    "    return \" \".join(new_text)"
   ],
   "id": "6b97b7b1ef04ccaf",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T17:46:30.276800Z",
     "start_time": "2025-04-18T17:46:28.806177Z"
    }
   },
   "cell_type": "code",
   "source": "df['review'] = df['review'].apply(chat_conversion)",
   "id": "8329466a32772065",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T17:49:25.626340Z",
     "start_time": "2025-04-18T17:49:25.457452Z"
    }
   },
   "cell_type": "code",
   "source": "from textblob import TextBlob\n",
   "id": "c1d9d13ef6bf14c5",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T17:50:58.904703Z",
     "start_time": "2025-04-18T17:50:58.901692Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# incorrect words\n",
    "from textblob import Word\n",
    "def correct_spelling(text):\n",
    "    corrected_text = []\n",
    "    for word in text.split():\n",
    "        corrected_word = str(TextBlob(word).correct())\n",
    "        corrected_text.append(corrected_word)\n",
    "    return \" \".join(corrected_text)"
   ],
   "id": "8a7010696d3c429e",
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T17:52:34.973696200Z",
     "start_time": "2025-04-18T17:51:03.598852Z"
    }
   },
   "cell_type": "code",
   "source": "df['review'] = df['review'].apply(correct_spelling)",
   "id": "33d90834126b6321",
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[29]\u001B[39m\u001B[32m, line 1\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m1\u001B[39m df[\u001B[33m'\u001B[39m\u001B[33mreview\u001B[39m\u001B[33m'\u001B[39m] = \u001B[43mdf\u001B[49m\u001B[43m[\u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43mreview\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m.\u001B[49m\u001B[43mapply\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcorrect_spelling\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\pythonProject8\\.venv\\Lib\\site-packages\\pandas\\core\\series.py:4924\u001B[39m, in \u001B[36mSeries.apply\u001B[39m\u001B[34m(self, func, convert_dtype, args, by_row, **kwargs)\u001B[39m\n\u001B[32m   4789\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mapply\u001B[39m(\n\u001B[32m   4790\u001B[39m     \u001B[38;5;28mself\u001B[39m,\n\u001B[32m   4791\u001B[39m     func: AggFuncType,\n\u001B[32m   (...)\u001B[39m\u001B[32m   4796\u001B[39m     **kwargs,\n\u001B[32m   4797\u001B[39m ) -> DataFrame | Series:\n\u001B[32m   4798\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m   4799\u001B[39m \u001B[33;03m    Invoke function on values of Series.\u001B[39;00m\n\u001B[32m   4800\u001B[39m \n\u001B[32m   (...)\u001B[39m\u001B[32m   4915\u001B[39m \u001B[33;03m    dtype: float64\u001B[39;00m\n\u001B[32m   4916\u001B[39m \u001B[33;03m    \"\"\"\u001B[39;00m\n\u001B[32m   4917\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mSeriesApply\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   4918\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m   4919\u001B[39m \u001B[43m        \u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   4920\u001B[39m \u001B[43m        \u001B[49m\u001B[43mconvert_dtype\u001B[49m\u001B[43m=\u001B[49m\u001B[43mconvert_dtype\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   4921\u001B[39m \u001B[43m        \u001B[49m\u001B[43mby_row\u001B[49m\u001B[43m=\u001B[49m\u001B[43mby_row\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   4922\u001B[39m \u001B[43m        \u001B[49m\u001B[43margs\u001B[49m\u001B[43m=\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   4923\u001B[39m \u001B[43m        \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m=\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m-> \u001B[39m\u001B[32m4924\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\u001B[43m.\u001B[49m\u001B[43mapply\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\pythonProject8\\.venv\\Lib\\site-packages\\pandas\\core\\apply.py:1427\u001B[39m, in \u001B[36mSeriesApply.apply\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m   1424\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m.apply_compat()\n\u001B[32m   1426\u001B[39m \u001B[38;5;66;03m# self.func is Callable\u001B[39;00m\n\u001B[32m-> \u001B[39m\u001B[32m1427\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mapply_standard\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\pythonProject8\\.venv\\Lib\\site-packages\\pandas\\core\\apply.py:1507\u001B[39m, in \u001B[36mSeriesApply.apply_standard\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m   1501\u001B[39m \u001B[38;5;66;03m# row-wise access\u001B[39;00m\n\u001B[32m   1502\u001B[39m \u001B[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001B[39;00m\n\u001B[32m   1503\u001B[39m \u001B[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001B[39;00m\n\u001B[32m   1504\u001B[39m \u001B[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001B[39;00m\n\u001B[32m   1505\u001B[39m \u001B[38;5;66;03m#  Categorical (GH51645).\u001B[39;00m\n\u001B[32m   1506\u001B[39m action = \u001B[33m\"\u001B[39m\u001B[33mignore\u001B[39m\u001B[33m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(obj.dtype, CategoricalDtype) \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m-> \u001B[39m\u001B[32m1507\u001B[39m mapped = \u001B[43mobj\u001B[49m\u001B[43m.\u001B[49m\u001B[43m_map_values\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   1508\u001B[39m \u001B[43m    \u001B[49m\u001B[43mmapper\u001B[49m\u001B[43m=\u001B[49m\u001B[43mcurried\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mna_action\u001B[49m\u001B[43m=\u001B[49m\u001B[43maction\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconvert\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mconvert_dtype\u001B[49m\n\u001B[32m   1509\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1511\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(mapped) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(mapped[\u001B[32m0\u001B[39m], ABCSeries):\n\u001B[32m   1512\u001B[39m     \u001B[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001B[39;00m\n\u001B[32m   1513\u001B[39m     \u001B[38;5;66;03m#  See also GH#25959 regarding EA support\u001B[39;00m\n\u001B[32m   1514\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m obj._constructor_expanddim(\u001B[38;5;28mlist\u001B[39m(mapped), index=obj.index)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\pythonProject8\\.venv\\Lib\\site-packages\\pandas\\core\\base.py:921\u001B[39m, in \u001B[36mIndexOpsMixin._map_values\u001B[39m\u001B[34m(self, mapper, na_action, convert)\u001B[39m\n\u001B[32m    918\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(arr, ExtensionArray):\n\u001B[32m    919\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m arr.map(mapper, na_action=na_action)\n\u001B[32m--> \u001B[39m\u001B[32m921\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43malgorithms\u001B[49m\u001B[43m.\u001B[49m\u001B[43mmap_array\u001B[49m\u001B[43m(\u001B[49m\u001B[43marr\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmapper\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mna_action\u001B[49m\u001B[43m=\u001B[49m\u001B[43mna_action\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconvert\u001B[49m\u001B[43m=\u001B[49m\u001B[43mconvert\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\pythonProject8\\.venv\\Lib\\site-packages\\pandas\\core\\algorithms.py:1743\u001B[39m, in \u001B[36mmap_array\u001B[39m\u001B[34m(arr, mapper, na_action, convert)\u001B[39m\n\u001B[32m   1741\u001B[39m values = arr.astype(\u001B[38;5;28mobject\u001B[39m, copy=\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[32m   1742\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m na_action \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1743\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mlib\u001B[49m\u001B[43m.\u001B[49m\u001B[43mmap_infer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvalues\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmapper\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconvert\u001B[49m\u001B[43m=\u001B[49m\u001B[43mconvert\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1744\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m   1745\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m lib.map_infer_mask(\n\u001B[32m   1746\u001B[39m         values, mapper, mask=isna(values).view(np.uint8), convert=convert\n\u001B[32m   1747\u001B[39m     )\n",
      "\u001B[36mFile \u001B[39m\u001B[32mlib.pyx:2972\u001B[39m, in \u001B[36mpandas._libs.lib.map_infer\u001B[39m\u001B[34m()\u001B[39m\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[28]\u001B[39m\u001B[32m, line 6\u001B[39m, in \u001B[36mcorrect_spelling\u001B[39m\u001B[34m(text)\u001B[39m\n\u001B[32m      4\u001B[39m corrected_text = []\n\u001B[32m      5\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m word \u001B[38;5;129;01min\u001B[39;00m text.split():\n\u001B[32m----> \u001B[39m\u001B[32m6\u001B[39m     corrected_word = \u001B[38;5;28mstr\u001B[39m(\u001B[43mTextBlob\u001B[49m\u001B[43m(\u001B[49m\u001B[43mword\u001B[49m\u001B[43m)\u001B[49m\u001B[43m.\u001B[49m\u001B[43mcorrect\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[32m      7\u001B[39m     corrected_text.append(corrected_word)\n\u001B[32m      8\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[33m\"\u001B[39m\u001B[33m \u001B[39m\u001B[33m\"\u001B[39m.join(corrected_text)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\pythonProject8\\.venv\\Lib\\site-packages\\textblob\\blob.py:555\u001B[39m, in \u001B[36mBaseBlob.correct\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    553\u001B[39m tokens = nltk.tokenize.regexp_tokenize(\u001B[38;5;28mself\u001B[39m.raw, \u001B[33mr\u001B[39m\u001B[33m\"\u001B[39m\u001B[33m\\\u001B[39m\u001B[33mw+|[^\u001B[39m\u001B[33m\\\u001B[39m\u001B[33mw\u001B[39m\u001B[33m\\\u001B[39m\u001B[33ms]|\u001B[39m\u001B[33m\\\u001B[39m\u001B[33ms\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m    554\u001B[39m corrected = (Word(w).correct() \u001B[38;5;28;01mfor\u001B[39;00m w \u001B[38;5;129;01min\u001B[39;00m tokens)\n\u001B[32m--> \u001B[39m\u001B[32m555\u001B[39m ret = \u001B[33;43m\"\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mjoin\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcorrected\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    556\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m.\u001B[34m__class__\u001B[39m(ret)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\pythonProject8\\.venv\\Lib\\site-packages\\textblob\\blob.py:554\u001B[39m, in \u001B[36m<genexpr>\u001B[39m\u001B[34m(.0)\u001B[39m\n\u001B[32m    552\u001B[39m \u001B[38;5;66;03m# regex matches: word or punctuation or whitespace\u001B[39;00m\n\u001B[32m    553\u001B[39m tokens = nltk.tokenize.regexp_tokenize(\u001B[38;5;28mself\u001B[39m.raw, \u001B[33mr\u001B[39m\u001B[33m\"\u001B[39m\u001B[33m\\\u001B[39m\u001B[33mw+|[^\u001B[39m\u001B[33m\\\u001B[39m\u001B[33mw\u001B[39m\u001B[33m\\\u001B[39m\u001B[33ms]|\u001B[39m\u001B[33m\\\u001B[39m\u001B[33ms\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m--> \u001B[39m\u001B[32m554\u001B[39m corrected = (\u001B[43mWord\u001B[49m\u001B[43m(\u001B[49m\u001B[43mw\u001B[49m\u001B[43m)\u001B[49m\u001B[43m.\u001B[49m\u001B[43mcorrect\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m w \u001B[38;5;129;01min\u001B[39;00m tokens)\n\u001B[32m    555\u001B[39m ret = \u001B[33m\"\u001B[39m\u001B[33m\"\u001B[39m.join(corrected)\n\u001B[32m    556\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m.\u001B[34m__class__\u001B[39m(ret)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\pythonProject8\\.venv\\Lib\\site-packages\\textblob\\blob.py:115\u001B[39m, in \u001B[36mWord.correct\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    109\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mcorrect\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[32m    110\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33;03m\"\"\"Correct the spelling of the word. Returns the word with the highest\u001B[39;00m\n\u001B[32m    111\u001B[39m \u001B[33;03m    confidence using the spelling corrector.\u001B[39;00m\n\u001B[32m    112\u001B[39m \n\u001B[32m    113\u001B[39m \u001B[33;03m    .. versionadded:: 0.6.0\u001B[39;00m\n\u001B[32m    114\u001B[39m \u001B[33;03m    \"\"\"\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m115\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m Word(\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mspellcheck\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m[\u001B[32m0\u001B[39m][\u001B[32m0\u001B[39m])\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\pythonProject8\\.venv\\Lib\\site-packages\\textblob\\blob.py:107\u001B[39m, in \u001B[36mWord.spellcheck\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m     98\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mspellcheck\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[32m     99\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33;03m\"\"\"Return a list of (word, confidence) tuples of spelling corrections.\u001B[39;00m\n\u001B[32m    100\u001B[39m \n\u001B[32m    101\u001B[39m \u001B[33;03m    Based on: Peter Norvig, \"How to Write a Spelling Corrector\"\u001B[39;00m\n\u001B[32m   (...)\u001B[39m\u001B[32m    105\u001B[39m \u001B[33;03m    .. versionadded:: 0.6.0\u001B[39;00m\n\u001B[32m    106\u001B[39m \u001B[33;03m    \"\"\"\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m107\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43msuggest\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mstring\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\pythonProject8\\.venv\\Lib\\site-packages\\textblob\\en\\__init__.py:118\u001B[39m, in \u001B[36msuggest\u001B[39m\u001B[34m(w)\u001B[39m\n\u001B[32m    116\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34msuggest\u001B[39m(w):\n\u001B[32m    117\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33;03m\"\"\"Returns a list of (word, confidence)-tuples of spelling corrections.\"\"\"\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m118\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mspelling\u001B[49m\u001B[43m.\u001B[49m\u001B[43msuggest\u001B[49m\u001B[43m(\u001B[49m\u001B[43mw\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\pythonProject8\\.venv\\Lib\\site-packages\\textblob\\_text.py:1692\u001B[39m, in \u001B[36mSpelling.suggest\u001B[39m\u001B[34m(self, w)\u001B[39m\n\u001B[32m   1687\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m w.replace(\u001B[33m\"\u001B[39m\u001B[33m.\u001B[39m\u001B[33m\"\u001B[39m, \u001B[33m\"\u001B[39m\u001B[33m\"\u001B[39m).isdigit():\n\u001B[32m   1688\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m [(w, \u001B[32m1.0\u001B[39m)]  \u001B[38;5;66;03m# 1.5\u001B[39;00m\n\u001B[32m   1689\u001B[39m candidates = (\n\u001B[32m   1690\u001B[39m     \u001B[38;5;28mself\u001B[39m._known([w])\n\u001B[32m   1691\u001B[39m     \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._known(\u001B[38;5;28mself\u001B[39m._edit1(w))\n\u001B[32m-> \u001B[39m\u001B[32m1692\u001B[39m     \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._known(\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_edit2\u001B[49m\u001B[43m(\u001B[49m\u001B[43mw\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[32m   1693\u001B[39m     \u001B[38;5;129;01mor\u001B[39;00m [w]\n\u001B[32m   1694\u001B[39m )\n\u001B[32m   1695\u001B[39m candidates = [(\u001B[38;5;28mself\u001B[39m.get(c, \u001B[32m0.0\u001B[39m), c) \u001B[38;5;28;01mfor\u001B[39;00m c \u001B[38;5;129;01min\u001B[39;00m candidates]\n\u001B[32m   1696\u001B[39m s = \u001B[38;5;28mfloat\u001B[39m(\u001B[38;5;28msum\u001B[39m(p \u001B[38;5;28;01mfor\u001B[39;00m p, word \u001B[38;5;129;01min\u001B[39;00m candidates) \u001B[38;5;129;01mor\u001B[39;00m \u001B[32m1\u001B[39m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\pythonProject8\\.venv\\Lib\\site-packages\\textblob\\_text.py:1667\u001B[39m, in \u001B[36mSpelling._edit2\u001B[39m\u001B[34m(self, w)\u001B[39m\n\u001B[32m   1664\u001B[39m \u001B[38;5;250m\u001B[39m\u001B[33;03m\"\"\"Returns a set of words with edit distance 2 from the given word\"\"\"\u001B[39;00m\n\u001B[32m   1665\u001B[39m \u001B[38;5;66;03m# Of all spelling errors, 99% is covered by edit distance 2.\u001B[39;00m\n\u001B[32m   1666\u001B[39m \u001B[38;5;66;03m# Only keep candidates that are actually known words (20% speedup).\u001B[39;00m\n\u001B[32m-> \u001B[39m\u001B[32m1667\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mset\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43me2\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43me1\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_edit1\u001B[49m\u001B[43m(\u001B[49m\u001B[43mw\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43me2\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_edit1\u001B[49m\u001B[43m(\u001B[49m\u001B[43me1\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43me2\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\pythonProject8\\.venv\\Lib\\site-packages\\textblob\\_text.py:1667\u001B[39m, in \u001B[36m<genexpr>\u001B[39m\u001B[34m(.0)\u001B[39m\n\u001B[32m   1664\u001B[39m \u001B[38;5;250m\u001B[39m\u001B[33;03m\"\"\"Returns a set of words with edit distance 2 from the given word\"\"\"\u001B[39;00m\n\u001B[32m   1665\u001B[39m \u001B[38;5;66;03m# Of all spelling errors, 99% is covered by edit distance 2.\u001B[39;00m\n\u001B[32m   1666\u001B[39m \u001B[38;5;66;03m# Only keep candidates that are actually known words (20% speedup).\u001B[39;00m\n\u001B[32m-> \u001B[39m\u001B[32m1667\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mset\u001B[39m(e2 \u001B[38;5;28;01mfor\u001B[39;00m e1 \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m._edit1(w) \u001B[38;5;28;01mfor\u001B[39;00m e2 \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m._edit1(e1) \u001B[38;5;28;01mif\u001B[39;00m e2 \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m)\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T17:53:13.845865Z",
     "start_time": "2025-04-18T17:53:11.507478Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# remove stop words\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "def remove_stopwords(text):\n",
    "    word_tokens = word_tokenize(text)\n",
    "    filtered_text = [word for word in word_tokens if word not in stop_words]\n",
    "    return \" \".join(filtered_text)"
   ],
   "id": "a658863956e0310e",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\ASUS\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ASUS\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\ASUS\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping taggers\\averaged_perceptron_tagger.zip.\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\ASUS\\AppData\\Roaming\\nltk_data...\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T17:54:40.996084Z",
     "start_time": "2025-04-18T17:54:40.981178Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# remove emojis\n",
    "import emoji    \n",
    "def remove_emojis(text):\n",
    "    return emoji.replace_emoji(text, replace='')"
   ],
   "id": "b10dbffa4ba790e7",
   "outputs": [],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T17:56:40.804866Z",
     "start_time": "2025-04-18T17:56:40.801677Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# demojize\n",
    "def demojize(text):\n",
    "    return emoji.demojize(text)"
   ],
   "id": "9b55d8dbe56b1300",
   "outputs": [],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T17:58:07.219730Z",
     "start_time": "2025-04-18T17:58:07.216405Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# tokenization\n",
    "nltk.download('punkt')\n"
   ],
   "id": "e18d4d261a0c5f7",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\ASUS\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T17:59:24.744192Z",
     "start_time": "2025-04-18T17:59:24.741486Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# # word tokenization\n",
    "\n",
    "sent1 = \"Hello, how are you?\"\n",
    "sent1.split()"
   ],
   "id": "572f15e2469b3c51",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello,', 'how', 'are', 'you?']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 41
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T18:00:30.816093Z",
     "start_time": "2025-04-18T18:00:30.811950Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#sentence level tokenization\n",
    "from nltk.tokenize import sent_tokenize\n",
    "sent2 = \"Hello, how are you. I am fine.\"\n",
    "sent2.split('.')"
   ],
   "id": "b6716d8670d3dc31",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello, how are you', ' I am fine', '']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 43
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T18:04:45.553582Z",
     "start_time": "2025-04-18T18:04:43.683353Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "import nltk\n",
    "nltk.download('punkt')  # This is the real resource\n",
    "nltk.download('punkt_tab')\n",
    "\n",
    "\n",
    "# Sample sentence\n",
    "sent = \"Hello, how are you. I am fine.\"\n",
    "\n",
    "# Sentence tokenization (optional, but useful)\n",
    "sent_tokens = sent_tokenize(sent)\n",
    "print(\"Sentence tokens:\", sent_tokens)\n",
    "\n",
    "# Word tokenization\n",
    "word_tokens = word_tokenize(sent)\n",
    "print(\"Word tokens:\", word_tokens)\n"
   ],
   "id": "8370cbd70686b3b",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\ASUS\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\ASUS\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence tokens: ['Hello, how are you.', 'I am fine.']\n",
      "Word tokens: ['Hello', ',', 'how', 'are', 'you', '.', 'I', 'am', 'fine', '.']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data]   Unzipping tokenizers\\punkt_tab.zip.\n"
     ]
    }
   ],
   "execution_count": 48
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T18:06:12.830051Z",
     "start_time": "2025-04-18T18:05:59.824336Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Spacy - Tokenization\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(\"Hello, how are you. I am fine.\")\n",
    "for token in doc:\n",
    "    print(token.text, token.pos_, token.dep_)"
   ],
   "id": "9cae10dec8f324ef",
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[E050] Can't find model 'en_core_web_sm'. It doesn't seem to be a Python package or a valid path to a data directory.",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mOSError\u001B[39m                                   Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[49]\u001B[39m\u001B[32m, line 3\u001B[39m\n\u001B[32m      1\u001B[39m \u001B[38;5;66;03m# Spacy\u001B[39;00m\n\u001B[32m      2\u001B[39m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mspacy\u001B[39;00m\n\u001B[32m----> \u001B[39m\u001B[32m3\u001B[39m nlp = \u001B[43mspacy\u001B[49m\u001B[43m.\u001B[49m\u001B[43mload\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43men_core_web_sm\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[32m      4\u001B[39m doc = nlp(\u001B[33m\"\u001B[39m\u001B[33mHello, how are you. I am fine.\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m      5\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m token \u001B[38;5;129;01min\u001B[39;00m doc:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\pythonProject8\\.venv\\Lib\\site-packages\\spacy\\__init__.py:51\u001B[39m, in \u001B[36mload\u001B[39m\u001B[34m(name, vocab, disable, enable, exclude, config)\u001B[39m\n\u001B[32m     27\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mload\u001B[39m(\n\u001B[32m     28\u001B[39m     name: Union[\u001B[38;5;28mstr\u001B[39m, Path],\n\u001B[32m     29\u001B[39m     *,\n\u001B[32m   (...)\u001B[39m\u001B[32m     34\u001B[39m     config: Union[Dict[\u001B[38;5;28mstr\u001B[39m, Any], Config] = util.SimpleFrozenDict(),\n\u001B[32m     35\u001B[39m ) -> Language:\n\u001B[32m     36\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33;03m\"\"\"Load a spaCy model from an installed package or a local path.\u001B[39;00m\n\u001B[32m     37\u001B[39m \n\u001B[32m     38\u001B[39m \u001B[33;03m    name (str): Package name or model path.\u001B[39;00m\n\u001B[32m   (...)\u001B[39m\u001B[32m     49\u001B[39m \u001B[33;03m    RETURNS (Language): The loaded nlp object.\u001B[39;00m\n\u001B[32m     50\u001B[39m \u001B[33;03m    \"\"\"\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m51\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mutil\u001B[49m\u001B[43m.\u001B[49m\u001B[43mload_model\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m     52\u001B[39m \u001B[43m        \u001B[49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     53\u001B[39m \u001B[43m        \u001B[49m\u001B[43mvocab\u001B[49m\u001B[43m=\u001B[49m\u001B[43mvocab\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     54\u001B[39m \u001B[43m        \u001B[49m\u001B[43mdisable\u001B[49m\u001B[43m=\u001B[49m\u001B[43mdisable\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     55\u001B[39m \u001B[43m        \u001B[49m\u001B[43menable\u001B[49m\u001B[43m=\u001B[49m\u001B[43menable\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     56\u001B[39m \u001B[43m        \u001B[49m\u001B[43mexclude\u001B[49m\u001B[43m=\u001B[49m\u001B[43mexclude\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     57\u001B[39m \u001B[43m        \u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m=\u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     58\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\pythonProject8\\.venv\\Lib\\site-packages\\spacy\\util.py:472\u001B[39m, in \u001B[36mload_model\u001B[39m\u001B[34m(name, vocab, disable, enable, exclude, config)\u001B[39m\n\u001B[32m    470\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01min\u001B[39;00m OLD_MODEL_SHORTCUTS:\n\u001B[32m    471\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mIOError\u001B[39;00m(Errors.E941.format(name=name, full=OLD_MODEL_SHORTCUTS[name]))  \u001B[38;5;66;03m# type: ignore[index]\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m472\u001B[39m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mIOError\u001B[39;00m(Errors.E050.format(name=name))\n",
      "\u001B[31mOSError\u001B[39m: [E050] Can't find model 'en_core_web_sm'. It doesn't seem to be a Python package or a valid path to a data directory."
     ]
    }
   ],
   "execution_count": 49
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T18:08:27.056788Z",
     "start_time": "2025-04-18T18:08:27.053847Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# stemming\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "ps = PorterStemmer()"
   ],
   "id": "fa01481c911aa4a0",
   "outputs": [],
   "execution_count": 50
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T18:10:33.228534Z",
     "start_time": "2025-04-18T18:10:33.225907Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Sample text\n",
    "text = \"Walking and talks are different. I am walking and talking., walk walking talk talk\"\n",
    "# Tokenize the text\n",
    "words = word_tokenize(text)\n",
    "# Perform stemming\n",
    "stemmed_words = [ps.stem(word) for word in words]"
   ],
   "id": "4b8972c07a4071cf",
   "outputs": [],
   "execution_count": 54
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T18:10:34.004913Z",
     "start_time": "2025-04-18T18:10:34.001728Z"
    }
   },
   "cell_type": "code",
   "source": "print(\"Original words:\", words)",
   "id": "9023fcd8b1874c5b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original words: ['Walking', 'and', 'talks', 'are', 'different', '.', 'I', 'am', 'walking', 'and', 'talking.', ',', 'walk', 'walking', 'talk', 'talk']\n"
     ]
    }
   ],
   "execution_count": 55
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T18:10:38.169966Z",
     "start_time": "2025-04-18T18:10:38.166620Z"
    }
   },
   "cell_type": "code",
   "source": "print(\"Stemmed words:\", stemmed_words)",
   "id": "8559fd6e86313dfe",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stemmed words: ['walk', 'and', 'talk', 'are', 'differ', '.', 'i', 'am', 'walk', 'and', 'talking.', ',', 'walk', 'walk', 'talk', 'talk']\n"
     ]
    }
   ],
   "execution_count": 56
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T18:12:20.247327Z",
     "start_time": "2025-04-18T18:12:20.243862Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Lemmatization and stemming difference is - \n",
    "# stemming - walk, walking, walked -> walk\n",
    "\n",
    "# lemmatization - walk, walking, walked -> walk \n",
    "# lemmatization - better, best -> good\n",
    "\n",
    "# lemmatization - better, best -> good"
   ],
   "id": "40881ea894ecf8ce",
   "outputs": [],
   "execution_count": 57
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T18:12:53.776704Z",
     "start_time": "2025-04-18T18:12:53.774205Z"
    }
   },
   "cell_type": "code",
   "source": "# generally lemmatization is better than stemming because it gives the root word. root word is the word which is in the dictionary. ",
   "id": "cd21a9e6100e6244",
   "outputs": [],
   "execution_count": 58
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "dbb28403ce6e33a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
